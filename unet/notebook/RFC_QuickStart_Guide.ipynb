{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f92bbb09-2961-4aee-98e9-6080259cbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(globals()['_dh'][0])\n",
    "os.chdir('..')\n",
    "# print(os.path.abspath(os.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2abb7b1d-3191-42ff-82e7-94e9ad2ff195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 15:11:29.180909: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-28 15:11:29.777151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30976 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import rfcutils\n",
    "import h5py\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "get_db = lambda p: 10*np.log10(p)\n",
    "get_pow = lambda s: np.mean(np.abs(s)**2, axis=-1)\n",
    "get_sinr = lambda s, i: get_pow(s)/get_pow(i)\n",
    "get_sinr_db = lambda s, i: get_db(get_sinr(s,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72d61a6-34c5-4dda-be08-10259ba031a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_len = 40960\n",
    "n_per_batch = 100\n",
    "all_sinr = np.arange(-30, 0.1, 3)\n",
    "\n",
    "seed_number = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f7f5af-94b0-4e26-b358-2463b1c564ff",
   "metadata": {},
   "source": [
    "## Creating Training Set (Small Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ae3f93-68ec-4af5-9c01-ceff00fd70fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain the relevant generation and demodulation function for SOI type; we will focus on QPSK and OFDMQPSK for now\n",
    "def get_soi_generation_fn(soi_sig_type):\n",
    "    if soi_sig_type == 'QPSK':\n",
    "        generate_soi = lambda n, s_len: rfcutils.generate_qpsk_signal(n, s_len//16)\n",
    "        demod_soi = rfcutils.qpsk_matched_filter_demod\n",
    "    # elif soi_sig_type == 'QAM16':\n",
    "    #     generate_soi = lambda n, s_len: rfcutils.generate_qam16_signal(n, s_len//16)\n",
    "    #     demod_soi = rfcutils.qam16_matched_filter_demod\n",
    "    # elif soi_sig_type ==  'QPSK2':\n",
    "    #     generate_soi = lambda n, s_len: rfcutils.generate_qpsk2_signal(n, s_len//4)\n",
    "    #     demod_soi = rfcutils.qpsk2_matched_filter_demod\n",
    "    elif soi_sig_type == 'OFDMQPSK':\n",
    "        generate_soi = lambda n, s_len: rfcutils.generate_ofdm_signal(n, s_len//80)\n",
    "        _,_,_,RES_GRID = rfcutils.generate_ofdm_signal(1, sig_len//80)\n",
    "        demod_soi = lambda s: rfcutils.ofdm_demod(s, RES_GRID)\n",
    "    else:\n",
    "        raise Exception(\"SOI Type not recognized\")\n",
    "    return generate_soi, demod_soi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df395fc-f727-472c-bccb-9928ae57476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_len = 40960\n",
    "n_per_batch = 100\n",
    "all_sinr = np.arange(-30, 0.1, 3)\n",
    "\n",
    "soi_type, interference_sig_type = 'QPSK', 'CommSignal2'\n",
    "\n",
    "seed_number = 0\n",
    "\n",
    "random.seed(seed_number)\n",
    "np.random.seed(seed_number)\n",
    "tf.random.set_seed(seed_number)\n",
    "\n",
    "generate_soi, demod_soi = get_soi_generation_fn(soi_type)\n",
    "\n",
    "with h5py.File(os.path.join('dataset', 'interferenceset_frame', interference_sig_type+'_raw_data.h5'),'r') as data_h5file:\n",
    "    sig_data = np.array(data_h5file.get('dataset'))\n",
    "    sig_type_info = data_h5file.get('sig_type')[()]\n",
    "    if isinstance(sig_type_info, bytes):\n",
    "        sig_type_info = sig_type_info.decode(\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c381346-69be-4d37-a74c-128aa9fdef9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 15:11:38.160649: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2023-08-28 15:12:47.550813: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "all_sig_mixture, all_sig1, all_bits1, meta_data = [], [], [], []\n",
    "for idx, sinr in enumerate(all_sinr):\n",
    "    sig1, _, bits1, _ = generate_soi(n_per_batch, sig_len)\n",
    "    sig2 = sig_data[np.random.randint(sig_data.shape[0], size=(n_per_batch)), :]\n",
    "\n",
    "    sig_target = sig1[:, :sig_len]\n",
    "\n",
    "    rand_start_idx2 = np.random.randint(sig2.shape[1]-sig_len, size=sig2.shape[0])\n",
    "    inds2 = tf.cast(rand_start_idx2.reshape(-1,1) + np.arange(sig_len).reshape(1,-1), tf.int32)\n",
    "    sig_interference = tf.experimental.numpy.take_along_axis(sig2, inds2, axis=1)\n",
    "\n",
    "    # Interference Coefficient\n",
    "    rand_gain = np.sqrt(10**(-sinr/10)).astype(np.float32)\n",
    "    rand_phase = tf.random.uniform(shape=[sig_interference.shape[0],1])\n",
    "    rand_gain = tf.complex(rand_gain, tf.zeros_like(rand_gain))\n",
    "    rand_phase = tf.complex(rand_phase, tf.zeros_like(rand_phase))\n",
    "    coeff = rand_gain * tf.math.exp(1j*2*np.pi*rand_phase)\n",
    "\n",
    "    sig_mixture = sig_target + sig_interference * coeff\n",
    "\n",
    "    all_sig_mixture.append(sig_mixture)\n",
    "    all_sig1.append(sig_target)\n",
    "    all_bits1.append(bits1)\n",
    "\n",
    "    actual_sinr = get_sinr_db(sig_target, sig_interference * coeff)\n",
    "    meta_data.append(np.vstack(([rand_gain.numpy().real for _ in range(n_per_batch)], [sinr for _ in range(n_per_batch)], actual_sinr, [soi_type for _ in range(n_per_batch)], [interference_sig_type for _ in range(n_per_batch)])))\n",
    "\n",
    "with tf.device('CPU'):\n",
    "    all_sig_mixture = tf.concat(all_sig_mixture, axis=0).numpy()\n",
    "    all_sig1 = tf.concat(all_sig1, axis=0).numpy()\n",
    "    all_bits1 = tf.concat(all_bits1, axis=0).numpy()\n",
    "\n",
    "meta_data = np.concatenate(meta_data, axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04bf5a-1ec9-4ac5-94c4-fde839cfd8e0",
   "metadata": {},
   "source": [
    "### TODO: Train a model\n",
    "\n",
    "***Input***: `all_sig_mixture` (and optionally, `meta_data`)\n",
    "\n",
    "***Output***: `all_sig1` and `all_bits1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d59539-0355-4269-a95a-88743dae46aa",
   "metadata": {},
   "source": [
    "## Example Inference/Output Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d56590c-f108-410c-835c-0971b59c9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_identifier = 'TestSet1Mixture'\n",
    "all_sig_mixture = np.load(os.path.join('dataset', f'{testset_identifier}_testmixture_{soi_type}_{interference_sig_type}.npy'))\n",
    "meta_data = np.load(os.path.join('dataset', f'{testset_identifier}_testmixture_{soi_type}_{interference_sig_type}_metadata.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a2e11a-22c9-4c88-b532-622275d79696",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_batch = 100\n",
    "all_sinr = np.arange(-30, 0.1, 3)\n",
    "\n",
    "id_string = 'ExampleNoMitigation'\n",
    "def run_inference(all_sig_mixture, meta_data, soi_type, interference_sig_type):   \n",
    "    \n",
    "    ##################################################\n",
    "    # Perform your inference here.\n",
    "    ##################################################\n",
    "    generate_soi, demod_soi = get_soi_generation_fn(soi_type)\n",
    "    \n",
    "    # E.g. No mitigation, standard matched filtering demodulation\n",
    "    sig1_est = all_sig_mixture\n",
    "    \n",
    "    bit_est = []\n",
    "    for idx, sinr_db in enumerate(all_sinr):\n",
    "        bit_est_batch, _ = demod_soi(sig1_est[idx*n_per_batch:(idx+1)*n_per_batch])\n",
    "        bit_est.append(bit_est_batch)\n",
    "    bit_est = tf.concat(bit_est, axis=0)\n",
    "    sig1_est, bit_est = sig1_est, bit_est.numpy()\n",
    "    ##################################################\n",
    "    \n",
    "    return sig1_est, bit_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3857f7c5-a4e9-4001-b7e9-137b054c2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig1_est, bit1_est = run_inference(all_sig_mixture, meta_data, soi_type, interference_sig_type)\n",
    "np.save(os.path.join('outputs', f'{id_string}_{testset_identifier}_estimated_soi_{soi_type}_{interference_sig_type}'), sig1_est)\n",
    "np.save(os.path.join('outputs', f'{id_string}_{testset_identifier}_estimated_bits_{soi_type}_{interference_sig_type}'), bit1_est)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rfsionna]",
   "language": "python",
   "name": "conda-env-.conda-rfsionna-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
